{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw37jHK/oO8T3qa+Nm2dTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3/blob/main/UnvielingMusicPreferrencesOnSpotify_MiniProject3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name:**  **Unveiling Music Preferences On Spotify**\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "**Project Type:** Exploratory Data Analysis + Hypothesis Testing + Interactive Visualizations + Predictive Modelling (Regression Models + Classification Models).\n",
        "\n",
        "**Contribution:** Individual\n",
        "\n",
        "### **Presented By:** Fida Taneem\n",
        "\n",
        "---------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "yUNfcEzadfp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary**\n",
        "\n",
        "This project aims to analyze Spotify user preferences and behaviors, providing insights into music and podcast consumption patterns. Using a mix of Exploratory Data Analysis (EDA), hypothesis testing, and predictive modeling (regression & classification), the project seeks to understand factors influencing subscription choices, listening habits, and satisfaction levels.\n",
        "\n",
        "--------------------------------------------------------------\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "1.To explore and visualize user listening patterns across demographics.\n",
        "\n",
        "2.To test statistical hypotheses (e.g., whether gender, age, or mood significantly influence preferences).\n",
        "\n",
        "3.To build predictive models for:\n",
        "\n",
        "  Regression → Predicting user ratings for music recommendations.\n",
        "\n",
        "  Classification → Predicting subscription plan preferences, podcast frequency, or favorite genres.\n",
        "\n",
        "4.To generate actionable insights for Spotify’s personalization and marketing strategies.\n",
        "\n",
        "### **Business Context**\n",
        "\n",
        "Spotify operates in a highly competitive streaming industry where user engagement and subscription retention are critical. Understanding listener behavior can:\n",
        "\n",
        "1. Help personalize playlists and improve recommendation systems.\n",
        "\n",
        "2. Guide targeted marketing campaigns for premium subscriptions.\n",
        "\n",
        "3. Optimize podcast offerings based on listener satisfaction and frequency.\n",
        "\n",
        "By analyzing real user data, this project provides insights that align with Spotify’s business goals of increasing premium conversions and enhancing user experience."
      ],
      "metadata": {
        "id": "N3-C33HTdfZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------"
      ],
      "metadata": {
        "id": "pOXueHTHdfWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Subject:** Business Analytics and Consumer Behavior (with ML)\n",
        "\n",
        "### **Data Source:** Survey-based dataset capturing Spotify users’ preferences.\n",
        "---------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "-vDjHsGwdfSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Overview:**\n",
        "\n",
        "**1.Rows**: 520 users\n",
        "\n",
        "**2.Columns:** 20 attributes covering:\n",
        "\n",
        "  *Demographics: Age, Gender\n",
        "\n",
        "  *Usage: Listening devices, usage period\n",
        "\n",
        "  *Subscriptions: Current plan, premium willingness, preferred plan\n",
        "\n",
        "  *Music Preferences: Favorite genre, time slots, mood influences, frequency, exploration method, recommendation rating\n",
        "\n",
        "  *Podcasts: Frequency, genre, format, host preference, duration, satisfaction\n",
        "\n",
        "### **About The DataSet**\n",
        "\n",
        "\n",
        "    1)Age - Age group of user?\n",
        "\n",
        "    2)Gender - Gender of user?\n",
        "\n",
        "    3)spotify_usage_period - How long have you been using Spotify?\n",
        "\n",
        "    4)spotify_listening_device - Which of the following devices do you primarily use to listen to Spotify?\n",
        "\n",
        "    5)spotify_subscription_plan - Which Spotify subscription plan do you currently have?\n",
        "\n",
        "    6)premium_sub_willingness - Are you willing to take a premium subscription or willing to continue with premium subscription in future?\n",
        "\n",
        "    7)preffered_premium_plan - If premium or willing to take premium, what amount do you pay for the subscription?\n",
        "\n",
        "    8)preferred_listening_content - What do you prefer to listen more?\n",
        "\n",
        "    9)fav_music_genre - What genre(s) of music do you enjoy the most?\n",
        "\n",
        "    10)music_time_slot - What is your favourite time slot to listen to music?\n",
        "\n",
        "    11)music_Influencial_mood - When it comes to listening to music, which of the following moods or situations most strongly influences your choice of music?\n",
        "\n",
        "    12)music_lis_frequency - When do you listen to music more often?\n",
        "\n",
        "    13)music_expl_method - How do you discover new music on Spotify?\n",
        "\n",
        "    14)music_recc_rating - How do you rate the spotify music recommendations?\n",
        "\n",
        "    15)pod_lis_frequency - How often do you listen to Podcast?\n",
        "\n",
        "    16)fav_pod_genre - What genre(s) of Podcast do you enjoy the most?\n",
        "\n",
        "    17)preffered_pod_format - What podcast format you generally prefer?\n",
        "\n",
        "    18)pod_host_preference - Are you more inclined to listen to podcasts from unknown personalities, or do you prefer podcasts hosted by well-known individuals?\n",
        "\n",
        "    19)preffered_pod_duration - Do you prefer shorter podcast episodes (under 30 minutes) or longer episodes (over 30 minutes)\n",
        "\n",
        "    20)pod_variety_satisfaction - Are you satisfied with the variety and availability of podcasts on Spotify?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "pP0eULXmdfNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**\n",
        "\n",
        "**1. Data Collection**\n",
        "\n",
        "Dataset: Spotify survey responses.\n",
        "\n",
        "Variables: Demographics (Age, Gender), usage behavior (devices, time, subscription), preferences (genre, podcasts).\n",
        "\n",
        "Target: preffered_premium_plan.\n",
        "\n",
        "**2. Cleaning**\n",
        "\n",
        "Replace \"None\" with NaN.\n",
        "\n",
        "Impute categorical NaN with mode, numeric with median.\n",
        "\n",
        "Standardize categories (case, spacing).\n",
        "\n",
        "Remove duplicates.\n",
        "\n",
        "Check class balance of preffered_premium_plan.\n",
        "\n",
        "**3. Feature Engineering**\n",
        "\n",
        "Age bins: Teen (12–20), Young Adult (20–35), Adult (35–60), Senior (60+).\n",
        "\n",
        "Usage duration: Short (<1 yr), Medium (1–2 yrs), Long (>2 yrs).\n",
        "\n",
        "Simplify device categories.\n",
        "\n",
        "Extract listening preference: music vs podcast.\n",
        "\n",
        "Encode: Label encode binary vars, one-hot encode multi-class.\n",
        "\n",
        "Scale numeric features (music_recc_rating, pod_variety_satisfaction)."
      ],
      "metadata": {
        "id": "0V3FsnjOe3ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "gtEXq6t1fXc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Techniques Used**\n",
        "\n",
        "\n",
        "\n",
        "-------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "uMXLe3R6fX1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EDA:**\n",
        "\n",
        "Frequency distributions, cross-tabs, heatmaps, bar charts, violin plots, interactive visuals (Plotly/Seaborn).\n",
        "\n",
        "## **Hypothesis Testing:**\n",
        "t-tests for mean differences.\n",
        "\n",
        "## **Regression:**\n",
        "Linear,Multiple regression to predict recommendation ratings.\n",
        "L1 & L2 Regularization, Elastic net Regression.\n",
        "\n",
        "## **Classification:**\n",
        "Logistic Regression, Decision Trees,KNN, GBM, XGBoost, LightBoost to predict subscription plans or genre preference.\n",
        "\n",
        "## **Model Evaluation:**\n",
        "Accuracy, Precision, Recall, F1-score, R², RMSE depending on the task.\n",
        "\n",
        "--------"
      ],
      "metadata": {
        "id": "RPfVt-2efY_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link:**\n",
        "\n",
        "https://github.com/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3\n",
        "\n",
        "--------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "cTYgfJV4fY5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Begin!**\n",
        "------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "VHzQJcLtfYxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing the Libraries**"
      ],
      "metadata": {
        "id": "_a-1BmNdfYot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RJJaNmcVte"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Modeling & utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "# Regression models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Classification models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset into Google Colab"
      ],
      "metadata": {
        "id": "vvZpYQ4lWAH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_music = pd.read_csv(\"https://raw.githubusercontent.com/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3/main/Spotify_data.csv\")\n",
        "\n",
        "#Creating a copy of the dataframe to perform necessary feature engineering, so as to keep the source data unchanged.\n",
        "\n",
        "df = df_music.copy()\n"
      ],
      "metadata": {
        "id": "IMv7OnMCV9BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Checking if the features are copied correctly\n",
        "\n",
        "display(df_music.head())\n",
        "print('\\n\\n')\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "YA685N9xV89a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display first 5 rows\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "CWn1d7qbV86K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display last 5 rows\n",
        "display(df.tail())"
      ],
      "metadata": {
        "id": "y0kBQ2zwV82o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display random 5 rows\n",
        "display(df.sample(5))\n"
      ],
      "metadata": {
        "id": "WqXLaGEEV8ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Display the shape of the datraframe.\n",
        "\n",
        "display(df.shape)\n",
        "\n",
        "print(f'The dataframe has {df.shape[0]} rows and {df.shape[1]} columns.')"
      ],
      "metadata": {
        "id": "oceYzRPkV8q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Information\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "WWLoBtMGV8m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total unique values in the dataframe\n",
        "\n",
        "df.nunique()\n"
      ],
      "metadata": {
        "id": "XztkR4ZqV8f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"fav_music_genre\"].unique()"
      ],
      "metadata": {
        "id": "4M0rhm4BV8cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"preffered_pod_format\"].unique()"
      ],
      "metadata": {
        "id": "-qAgODEEV8Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding total null values in each column"
      ],
      "metadata": {
        "id": "6BXECl_8lh_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Null values in the dataset\n",
        "\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "rGHoTnGXlhur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualizing the missing values using missingno\n",
        "\n",
        "msno.matrix(df, figsize=(12,6))\n",
        "plt.title(\"Missingness matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7zcswSWXV8VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualizing the missing values with heatmap using seaborn\n",
        "sns.heatmap(df.isnull(),\n",
        "            cmap=\"coolwarm\",  # any matplotlib colormap\n",
        "            cbar=False,\n",
        "            yticklabels=False)\n",
        "\n",
        "plt.title(\"Colored Missingness Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CzvC3v5IV8PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"None\" with NaN\n",
        "df = df.replace(\"None\", np.nan)"
      ],
      "metadata": {
        "id": "IGfQ3d-2V8Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip spaces & standardize categories\n",
        "for col in df.select_dtypes(include=\"object\").columns:\n",
        "    df[col] = df[col].astype(str).str.strip().str.title().replace(\"Nan\", np.nan)"
      ],
      "metadata": {
        "id": "1LnWmse1V8BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding total duplicates in the dataset"
      ],
      "metadata": {
        "id": "fWeR_xJasj3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Duplicates in the dataset\n",
        "\n",
        "print(\"Duplicates in the Dataset:\",df.duplicated().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "ECKGuPyLV79H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the duplicates , if exists\n",
        "df= df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "TqiNM5ecV75K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the variables"
      ],
      "metadata": {
        "id": "D943RXZ6vVM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "\n",
        "print(\"\\nFeatures in Source Dataset: \",df_music.columns.tolist())\n",
        "\n",
        "print(\"\\nFeatures in Copy of DataSet: \",df.columns.tolist())"
      ],
      "metadata": {
        "id": "BcM-g_cHV7x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Describing dataset\n",
        "\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "KlHFbrk6V7sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "    else:\n",
        "        df[col] = df[col].fillna(df[col].median())\n"
      ],
      "metadata": {
        "id": "Gv9NknmBV7pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop empty/unusable columns\n",
        "if \"pod_variety_satisfaction\" in df.columns and df[\"pod_variety_satisfaction\"].nunique() == 0:\n",
        "    df = df.drop(columns=[\"pod_variety_satisfaction\"])\n",
        "\n",
        "# Drop duplicates if any\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "BFvFIynaYXTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **What did i know about this dataset?**"
      ],
      "metadata": {
        "id": "RRqHQgHPyX6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset**\n",
        "Survey-based dataset capturing Spotify users’ demographics, listening habits, preferences, and satisfaction ratings.\n",
        "\n",
        "### **Structure**\n",
        "\n",
        "**Demographics:** Age, Gender.\n",
        "\n",
        "**Usage Behavior:** Subscription plan, usage duration, listening device, listening time slot.\n",
        "\n",
        "**Preferences**: Favorite music genre, favorite podcast genre, content preference.\n",
        "\n",
        "**Satisfaction Ratings:** Music recommendation rating, podcast variety satisfaction.\n",
        "\n",
        "**Target:** preffered_premium_plan (e.g., Free, Family, Individual, Student).\n",
        "\n",
        "### **Coverage**\n",
        "Represents diverse user groups with varying age, gender, listening habits, and premium plan interests.\n",
        "\n",
        "### **Purpose**\n",
        "To study user behavior, explore patterns in listening habits, test hypotheses about demographics vs. preferences, and build predictive models for premium plan adoption.\n",
        "\n",
        "### **Value**\n",
        "\n",
        "Provides insights for music platform analytics, marketing strategies, and machine learning applications in recommendation systems and customer segmentation.\n",
        "\n",
        "---------------"
      ],
      "metadata": {
        "id": "eZvAIPA9yV3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "\n",
        "Despite Spotify’s advanced recommendation system, there is scope to improve:\n",
        "\n",
        "Understanding listener segments and their content preferences.\n",
        "\n",
        "Identifying key drivers of premium subscription willingness.\n",
        "\n",
        "Predicting recommendation satisfaction to refine personalization.\n",
        "\n",
        "    This project seeks to answer:\n",
        "\n",
        "\n",
        "    1. What factors influence music and podcast choices?\n",
        "\n",
        "    2. Which demographics are more likely to subscribe to premium?\n",
        "\n",
        "    3. Can user satisfaction be predicted based on listening behavior?\n",
        "\n",
        "-------------------------"
      ],
      "metadata": {
        "id": "Tf0kc16XDVgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Detect And Treat Outliers**"
      ],
      "metadata": {
        "id": "kEMNzpL9z2Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert numeric columns properly\n",
        "for col in [\"music_recc_rating\", \"pod_variety_satisfaction\"]:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "\n",
        "\n",
        "# Save copy before treatment\n",
        "df_before = df.copy()\n",
        "\n",
        "\n",
        "\n",
        "# Function to detect outliers using IQR\n",
        "def detect_outliers_iqr(data, col):\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    return data[(data[col] < lower) | (data[col] > upper)]\n",
        "\n",
        "# Treat outliers by capping (Winsorization)\n",
        "for col in [\"music_recc_rating\", \"pod_variety_satisfaction\"]:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    df[col] = np.where(df[col] > upper, upper,\n",
        "                       np.where(df[col] < lower, lower, df[col]))\n",
        "\n",
        "\n",
        "# Visualization: Boxplots before vs after\n",
        "\n",
        "for col in [\"music_recc_rating\", \"pod_variety_satisfaction\"]:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    sns.boxplot(y=df_before[col].dropna(), ax=axes[0], color=\"skyblue\")\n",
        "    axes[0].set_title(f\"{col} - Before Capping\")\n",
        "\n",
        "    sns.boxplot(y=df[col].dropna(), ax=axes[1], color=\"lightgreen\")\n",
        "    axes[1].set_title(f\"{col} - After Capping\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Ao7y-bg5V7lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Visualizations**"
      ],
      "metadata": {
        "id": "n5Y2c3KwZJy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "881QZAU0Z-PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## 1. Distribution of Music Recommendation Ratings\n",
        "\n"
      ],
      "metadata": {
        "id": "SMcfmKI_ZdbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig1 = px.histogram(df, x=\"music_recc_rating\", nbins=5, title=\"Music Recommendation Rating Distribution\")\n",
        "fig1.show()"
      ],
      "metadata": {
        "id": "NAeqccEVV7b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        "Most users rate Spotify’s recommendations positively (ratings clustered at 4–5). Few low ratings indicate general satisfaction."
      ],
      "metadata": {
        "id": "utuP2GlSZuoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Gender Distribution"
      ],
      "metadata": {
        "id": "eMm2oJ_WaB3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"Gender\" in df.columns:\n",
        "    fig2 = px.pie(df, names=\"Gender\", title=\"Gender Distribution\")\n",
        "    fig2.show()"
      ],
      "metadata": {
        "id": "nHRu8UvtV7YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        " Gender distribution highlights whether responses are balanced. If skewed, results may reflect biases of one group more strongly.\n",
        " Female group of gender dominates the distribution."
      ],
      "metadata": {
        "id": "umFjHsC8avu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Subscription Plan Distribution"
      ],
      "metadata": {
        "id": "fPf0PxGWbAeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"spotify_subscription_plan\" in df.columns:\n",
        "    fig3 = px.pie(df, names=\"spotify_subscription_plan\", title=\"Subscription Plan Usage\")\n",
        "    fig3.show()"
      ],
      "metadata": {
        "id": "gmeCxFiGV7Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        "Most users are on the Free plan, with fewer Premium subscribers, showing an opportunity for conversion strategies."
      ],
      "metadata": {
        "id": "Pzq6SIdXbUhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Age vs Music Recommendation Rating"
      ],
      "metadata": {
        "id": "GTpVQgmbbnwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"Age\" in df.columns:\n",
        "    fig4 = px.box(df, x=\"Age\", y=\"music_recc_rating\", title=\"Music Rec Rating by Age Group\")\n",
        "    fig4.show()"
      ],
      "metadata": {
        "id": "sYjGR_XIV7Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        "Younger users (18–24) may give slightly higher ratings compared to older groups, showing stronger alignment with Spotify’s recommendation system."
      ],
      "metadata": {
        "id": "gqEZ3K9ecsM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Device vs Music Recommendation Rating"
      ],
      "metadata": {
        "id": "kZFlyG0Wc9rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"spotify_listening_device\" in df.columns:\n",
        "    fig5 = px.violin(df, x=\"spotify_listening_device\", y=\"music_recc_rating\", box=True, title=\"Music Rec Rating by Device\")\n",
        "    fig5.show()"
      ],
      "metadata": {
        "id": "tXjLsAMNdDuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        " Mobile users tend to rate recommendations higher, while desktop users show more spread, suggesting different experience quality across platforms."
      ],
      "metadata": {
        "id": "FRty52smdnhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Favourite Genre Distribution"
      ],
      "metadata": {
        "id": "vuuLRg6nd1-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre_counts = df['fav_music_genre'].value_counts().reset_index()\n",
        "genre_counts.columns = ['genre', 'count']\n",
        "fig6 = px.bar(genre_counts.sort_values(\"count\", ascending=False),\n",
        "              x=\"genre\", y=\"count\",\n",
        "              title=\"Favorite Music Genres\",\n",
        "              labels={\"genre\": \"Genre\", \"count\": \"Number of Users\"})\n",
        "fig6.show()\n"
      ],
      "metadata": {
        "id": "QKgrz8Rxd7c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        "This shows which music genres are most popular among users. The top genres reflect the dominant music tastes,\n",
        "    helping Spotify personalize playlists and target specific listener groups.\n"
      ],
      "metadata": {
        "id": "naW20hBid6le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Favorite Podcast Genres"
      ],
      "metadata": {
        "id": "Tbx_ZocQgNdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pod_counts = df['fav_pod_genre'].value_counts().reset_index()\n",
        "pod_counts.columns = ['podcast_genre', 'count']\n",
        "fig7 = px.bar(pod_counts.sort_values(\"count\", ascending=False),\n",
        "              x=\"podcast_genre\", y=\"count\",\n",
        "              title=\"Favorite Podcast Genres\",\n",
        "              labels={\"podcast_genre\": \"Podcast Genre\", \"count\": \"Number of Users\"})\n",
        "fig7.show()"
      ],
      "metadata": {
        "id": "lW2T4fNDg56I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Comedy and News/Politics podcasts are most preferred, indicating interest in both entertainment and current affairs."
      ],
      "metadata": {
        "id": "4p-dT5YYhSS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Age vs Subscription Plan"
      ],
      "metadata": {
        "id": "nXvtXxXehDpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig3 = px.sunburst(\n",
        "    df.fillna({\"Age\": \"Unknown\", \"spotify_subscription_plan\": \"Unknown\"}),\n",
        "    path=[\"Age\", \"spotify_subscription_plan\"],\n",
        "    title=\"Age vs Subscription Plan\"\n",
        ")\n",
        "fig3.show()"
      ],
      "metadata": {
        "id": "NcsdRwHgV6-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        "Majority of 20–35-year-olds use Free plan.\n",
        "\n",
        "Younger users (<20) also skew Free; older users (35–60) are a smaller segment."
      ],
      "metadata": {
        "id": "8YP0tYGZixz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 9. Polar Chart – Music Time Slots"
      ],
      "metadata": {
        "id": "sVcsjhy_i1yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_counts = df['music_time_slot'].value_counts().reset_index()\n",
        "time_counts.columns = ['time_slot', 'count']\n",
        "fig7 = px.line_polar(time_counts, r=\"count\", theta=\"time_slot\",\n",
        "                     line_close=True, title=\"Music Listening by Time Slot\")\n",
        "fig7.show()"
      ],
      "metadata": {
        "id": "XZaz5EybjHZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights**:\n",
        "\n",
        "Peak listening occurs during evening and night hours.\n",
        "\n",
        "Early morning slots see minimal activity."
      ],
      "metadata": {
        "id": "OgXISUIrktub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More Visuals"
      ],
      "metadata": {
        "id": "h_d3Ubm4jnQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Funnel Chart – Music Listening Frequency\n",
        "freq_counts = df['music_lis_frequency'].value_counts().reset_index()\n",
        "freq_counts.columns = ['frequency', 'count']\n",
        "fig8 = px.funnel(freq_counts, x=\"count\", y=\"frequency\",\n",
        "                 title=\"Music Listening Frequency Funnel\")\n",
        "fig8.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "H2aO4gbNV62F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "Most users listen occasionally, fewer are daily listeners.\n",
        "\n",
        "Shows potential for increasing engagement among casual listeners."
      ],
      "metadata": {
        "id": "QMUi4bc9k4zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Word Cloud – Favorite Genres (custom approach)\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "genre_text = \" \".join(df['fav_music_genre'].dropna().astype(str))\n",
        "wc = WordCloud(width=800, height=400, background_color=\"white\").generate(genre_text)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Word Cloud of Favorite Genres\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7SZYgOINV6zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Visual emphasis on top genres like Pop, Rap, Melody.\n",
        "\n",
        "Quick glance at trends in musical preferences."
      ],
      "metadata": {
        "id": "jlWiKY_vlHRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Bubble Chart – Podcast Genre Popularity\n",
        "pod_counts = df['fav_pod_genre'].value_counts().reset_index()\n",
        "pod_counts.columns = ['podcast_genre', 'count']\n",
        "fig10 = px.scatter(pod_counts, x=\"podcast_genre\", y=\"count\",\n",
        "                   size=\"count\", color=\"podcast_genre\",\n",
        "                   title=\"Podcast Genre Popularity (Bubble Chart)\")\n",
        "fig10.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "eL3fc_aMV6vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Popular podcasts include True Crime, News, and Comedy.\n",
        "\n",
        "Bubble size highlights dominant podcast preferences."
      ],
      "metadata": {
        "id": "597zModZldFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parallel Categories – Age, Device, Subscription\n",
        "fig11 = px.parallel_categories(df, dimensions=[\"Age\", \"spotify_listening_device\", \"spotify_subscription_plan\"],\n",
        "                               title=\"Age, Device, and Subscription Patterns\")\n",
        "fig11.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ek747kc1V6sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Younger users primarily use smartphones + Free plan.\n",
        "\n",
        "Older users show mixed device usage and slightly higher Premium adoption."
      ],
      "metadata": {
        "id": "8zvvFSG3lkNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Heatmap – Crosstab of Music vs Podcast Frequency\n",
        "cross = pd.crosstab(df['music_lis_frequency'], df['pod_lis_frequency'])\n",
        "fig12 = px.imshow(cross, text_auto=True,\n",
        "                  title=\"Music vs Podcast Listening Frequency\")\n",
        "fig12.show()"
      ],
      "metadata": {
        "id": "y_eZ1vqUV6pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Users who listen frequently to music also tend to be frequent podcast listeners.\n",
        "\n",
        "Identifies potential for cross-promotions between music and podcasts."
      ],
      "metadata": {
        "id": "RW9A0_nAl3bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig_anim = px.bar(\n",
        "    df,\n",
        "    x='music_time_slot',\n",
        "    y='music_lis_frequency',\n",
        "    color='spotify_subscription_plan',\n",
        "    animation_frame='Age',\n",
        "    range_y=[0, df['music_lis_frequency'].max()],\n",
        "    title=\"Listening Frequency Over Time Slots by Age\"\n",
        ")\n",
        "fig_anim.show()"
      ],
      "metadata": {
        "id": "xKz3JGB3V6lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Reveals peak engagement times for different segments, actionable for notifications and playlist pushes."
      ],
      "metadata": {
        "id": "R7Ak5epBnT6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "\n",
        "# **EDA Based Conclusion**\n",
        "\n",
        "1. The project uncovers patterns in Spotify listening behavior and highlights drivers of premium subscription adoption.\n",
        "\n",
        "2. Predictive models provide a way to forecast user satisfaction and preferences, aiding in personalization.\n",
        "\n",
        "3. Insights can help Spotify refine recommendation algorithms, marketing campaigns, and product strategies.\n",
        "\n",
        "------------------"
      ],
      "metadata": {
        "id": "OlnraaorjsuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hypothesis Testing**"
      ],
      "metadata": {
        "id": "rZEs5oKPnvW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "#Null Hypothesis (H₀): Music recommendation ratings do not differ across moods.\n",
        "\n",
        "#Alternate Hypothesis (H₁): At least one mood leads to a different rating.\n",
        "\n",
        "mood_groups = [df[df['music_Influencial_mood'] == mood]['music_recc_rating'].dropna() for mood in df['music_Influencial_mood'].unique()]\n",
        "\n",
        "f_stat_mood, p_val_mood = stats.f_oneway(*mood_groups)\n",
        "print(f\"F-statistic: {f_stat_mood:.3f}, P-value: {p_val_mood:.5f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EFq-85dSV6fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Interpretation:\n",
        "\n",
        "If p_val_mood < 0.05, reject H₀ → Mood significantly influences ratings.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "ShKfsiENoDIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Regression**\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "Q3ruXTinFVhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Linear Regression Model**"
      ],
      "metadata": {
        "id": "pAEbZVgqFi3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3/main/Spotify_data.csv\")\n",
        "\n",
        "# Features (drop target column) and target\n",
        "X = df.drop(columns=[\"music_recc_rating\"])\n",
        "y = df[\"music_recc_rating\"]\n",
        "\n",
        "# Convert categorical to numeric (dummy encoding)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Predictions:\", y_pred[:10])\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Model Accuracy (via R2):\", r2_score(y_test, y_pred) * 100, \"%\")\n"
      ],
      "metadata": {
        "id": "UU74j6wJ9VUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Insight – Linear Regression\n",
        "\n",
        "The Linear Regression model showed weak performance (R² ≈ 0.07), meaning it explains only ~7% of the variation in music_recc_rating. While predictions are in the right range, they mostly cluster around the mean, failing to capture the true differences. This indicates:\n",
        "\n",
        "music_recc_rating does not follow a simple linear relationship with features.\n",
        "\n",
        "The dataset may contain noise or subjective ratings.\n",
        "\n",
        "A more complex, non-linear model (Decision Tree, RandomForest, GBM, XGBoost, LightGBM) would likely perform better.\n",
        "\n",
        "------"
      ],
      "metadata": {
        "id": "rPAp5qcBJUwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Ridge Regression Model**"
      ],
      "metadata": {
        "id": "Xm8yv5sZIjt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_ridge)\n",
        "mse = mean_squared_error(y_test, y_pred_ridge)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred_ridge)\n",
        "\n",
        "print(\"Ridge Predictions:\", y_pred_ridge[:10])\n",
        "print(\"R2 Score:\", r2)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAE:\", mae)\n",
        "print(f\"Interpretation: Ridge explains {r2*100:.2f}% of variance, adding regularization to prevent overfitting.\")"
      ],
      "metadata": {
        "id": "KL1rnPOrH-4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Insight – Ridge Regression\n",
        "The Ridge Regression model performed slightly better than Linear Regression with an **R² ≈ 0.16**, explaining about **16.5% of the variation** in `music_recc_rating`.  \n",
        "Predictions are closer to the true values compared to simple linear regression, but still limited in capturing complex relationships.  \n",
        "The regularization in Ridge helps reduce overfitting and stabilize coefficients, yet the overall fit remains weak, suggesting that **non-linear models** may be more effective for this dataset.\n",
        "\n",
        "\n",
        "----\n"
      ],
      "metadata": {
        "id": "wsfp32cIM-uk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Lasso Regression Model**"
      ],
      "metadata": {
        "id": "vSKJkRkpNUau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso = Lasso(alpha=0.01, max_iter=10000)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "\n",
        "print(\"Predictions:\", y_pred_lasso[:10])\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_lasso))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_lasso))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred_lasso))"
      ],
      "metadata": {
        "id": "93hQMIYQJsEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insight – Lasso Regression\n",
        "The Lasso Regression model achieved an **R² ≈ 0.18**, explaining about **17.6% of the variance** in `music_recc_rating`.  \n",
        "Prediction errors (MAE ≈ 0.67, RMSE ≈ 0.84) are slightly better than Ridge, showing improved performance.  \n",
        "By applying L1 regularization, Lasso also performs feature selection by shrinking less important coefficients toward zero.  \n",
        "While this improves interpretability and reduces noise, the model still captures only a small portion of the underlying patterns, reinforcing the need for **non-linear approaches**.\n",
        "\n",
        "------\n"
      ],
      "metadata": {
        "id": "_ccHeCJTNTm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Elastic Net Regression Model**"
      ],
      "metadata": {
        "id": "9j5HR7kZN1mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "enet = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=10000)\n",
        "enet.fit(X_train, y_train)\n",
        "\n",
        "y_pred_enet = enet.predict(X_test)\n",
        "\n",
        "print(\"Predictions:\", y_pred_enet[:10])\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred_enet))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_enet))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_enet)))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred_enet))"
      ],
      "metadata": {
        "id": "xUXIihZkJsBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Insight – Elastic Net Regression\n",
        "The Elastic Net model achieved an **R² ≈ 0.18**, explaining about **18% of the variance** in `music_recc_rating`.  \n",
        "Its errors (MAE ≈ 0.66, RMSE ≈ 0.84) are slightly better than Ridge and close to Lasso, showing stable but modest improvements.  \n",
        "By combining **L1 (Lasso)** and **L2 (Ridge)** penalties, Elastic Net balances feature selection with coefficient stability, making it more robust when predictors are correlated.  \n",
        "Despite this advantage, the model still explains only a small fraction of the variance, confirming that **linear models are insufficient** and stronger non-linear methods are needed for better predictive accuracy.\n",
        "\n",
        "-----------\n"
      ],
      "metadata": {
        "id": "jibEVsh5N_bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**"
      ],
      "metadata": {
        "id": "9UyC00Z8PxHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3/main/Spotify_data.csv\")\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=[\"music_recc_rating\"])\n",
        "y = df[\"music_recc_rating\"]\n",
        "\n",
        "# Convert categorical features to numeric\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Handle missing values by filling with column mean\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model training\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Show first 10 predictions\n",
        "print(\"Predictions:\", y_pred[:10])\n"
      ],
      "metadata": {
        "id": "gNPvCSxhJr7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "1. The model achieves 46% accuracy, indicating moderate predictive performance.\n",
        "\n",
        "2. Class 3 is predicted best (high recall 0.72), while classes 2 and 5 are often misclassified.\n",
        "\n",
        "3. Many misclassifications occur between neighboring ratings, suggesting feature overlap.\n",
        "\n",
        "4. Class 4 is moderately predicted with balanced precision and recall.\n",
        "\n",
        "Overall, the model captures some patterns but struggles with minority or similar classes.\n",
        "\n",
        "Improvements could come from feature engineering, balancing classes, or using more powerful classifiers."
      ],
      "metadata": {
        "id": "dFqH0wEsTIMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Izd0d78CJrpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UopaDs7XJrl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification Models**\n",
        "\n",
        "------------------"
      ],
      "metadata": {
        "id": "ySrqenUaT0ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common setup"
      ],
      "metadata": {
        "id": "A-gL0x-jT7dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report,precision_score, recall_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Target = preffered_premium_plan\n",
        "Xc = df.drop(columns=[\"preffered_premium_plan\"])\n",
        "yc = df[\"preffered_premium_plan\"]\n",
        "\n",
        "# Encode categorical features\n",
        "Xc = pd.get_dummies(Xc, drop_first=True)\n",
        "\n",
        "# Train-test split\n",
        "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.2, random_state=42)\n",
        "\n",
        "def plot_cm(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o2lH2zHdTSnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN- K Nearest Neighborhood**"
      ],
      "metadata": {
        "id": "Ec-46ceVUdJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Fidaaz2521/UnveilingMusicPreferrencesOnSpotify_MiniProject3/main/Spotify_data.csv\")\n",
        "X = df.drop(columns=[\"music_recc_rating\"])\n",
        "y = df[\"music_recc_rating\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "X_train = X_train.fillna(X_train.mean())\n",
        "X_test = X_test.fillna(X_train.mean())\n",
        "\n",
        "# Scale features (KNN needs scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Blues')\n"
      ],
      "metadata": {
        "id": "ZeqvAtH9TSer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights for KNN**\n",
        "\n",
        "The model achieves ~30% accuracy, which is low compared to other classifiers.\n",
        "\n",
        "1. Class 3 is predicted best (recall = 0.42), but precision is still modest, indicating many false positives.\n",
        "\n",
        "2. Classes 2 and 4 have balanced but weak performance, with low recall (~0.19–0.36), showing difficulty in separating them.\n",
        "\n",
        "3. Class 5 is never predicted (recall = 0.00), highlighting severe class imbalance or lack of distinctive features.\n",
        "\n",
        "Overall, KNN struggles to generalize, possibly due to high feature overlap and sensitivity to noisy/multi-dimensional data.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "YwT9jZcRgKkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree (No Tuning)**"
      ],
      "metadata": {
        "id": "1pNbehB7edPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Greens')\n"
      ],
      "metadata": {
        "id": "FrRZaouzTSRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree (With Hyperparameter Tuning)**"
      ],
      "metadata": {
        "id": "YhwiJ-3JeXfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Decision Tree model & hyperparameters\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_dt = grid.best_estimator_\n",
        "y_pred = best_dt.predict(X_test)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Greens')\n"
      ],
      "metadata": {
        "id": "AF6tml7dTSbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights for Decision Tree**\n",
        "\n",
        "(Best Params: max_depth=3, min_samples_leaf=1, min_samples_split=2)\n",
        "\n",
        "The model achieves ~40% accuracy, showing moderate improvement over KNN.\n",
        "\n",
        "1. Class 3 and Class 4 are predicted reasonably well (recall = 0.56 each), indicating the tree is good at identifying majority/mid-range classes.\n",
        "\n",
        "2. Class 2 is completely missed (recall = 0.00), showing that the tree struggles with minority/low-frequency classes.\n",
        "\n",
        "3. Class 5 has high precision (0.67) but very low recall (0.12), suggesting the model is cautious in predicting this class but misses most of its instances.\n",
        "\n",
        "Overall, the Decision Tree captures some structure in the data but suffers from class imbalance and oversimplification due to shallow depth.\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "bAq6i0Kcgjpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GBM-Gradient Boosting Machine (No Tuning)**"
      ],
      "metadata": {
        "id": "9LMflW-KeTbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train GBM\n",
        "gbm = GradientBoostingClassifier(random_state=42)\n",
        "gbm.fit(X_train, y_train)\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Oranges')\n"
      ],
      "metadata": {
        "id": "LmeqeGw9W_ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GBM-Gradient Boosting Machine (With Hyperparameter Tuning)**"
      ],
      "metadata": {
        "id": "RXQJIhjoeKqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_gbm = grid.best_estimator_\n",
        "y_pred = best_gbm.predict(X_test)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Oranges')\n"
      ],
      "metadata": {
        "id": "cy-Vvk_NW_jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights for Gradient Boosting**\n",
        "\n",
        " (Best Params: learning_rate=0.2, max_depth=3, n_estimators=50)\n",
        "\n",
        "The model achieves ~45% accuracy, the best so far among the tested classifiers.\n",
        "\n",
        "1. Class 3 is predicted most effectively (recall = 0.72, F1 = 0.58), showing the model captures patterns for this group well.\n",
        "\n",
        "2. Class 4 is moderately predicted (precision = 0.52, recall = 0.42), with a balance between false positives and false negatives.\n",
        "\n",
        "3. Classes 2 and 5 remain weak (recall = 0.19 each), indicating challenges with minority categories and overlapping features.\n",
        "\n",
        "4. Class 1 has no representation in predictions, as there were no instances in the test set.\n",
        "\n",
        "Overall, Gradient Boosting captures non-linear relationships better than KNN and Decision Tree, but still struggles with minority/neighboring classes.\n",
        "\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "V-zF30CWg1Fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost (No Tuning)**"
      ],
      "metadata": {
        "id": "ubGp4Acod9MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Remap labels to start from 0\n",
        "y_train_mapped = y_train - 1\n",
        "y_test_mapped = y_test - 1\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "xgb_model.fit(X_train, y_train_mapped)\n",
        "\n",
        "# Predictions (use original X_test)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test_mapped, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test_mapped, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test_mapped, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test_mapped, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_mapped, y_pred, cmap='Purples')\n",
        "\n"
      ],
      "metadata": {
        "id": "lUaTf1unW_gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost (With Hyperparameter Tuning)**"
      ],
      "metadata": {
        "id": "x7-42R3zd456"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Map labels to start from 0\n",
        "y_train_mapped = y_train - 1\n",
        "y_test_mapped = y_test - 1\n",
        "\n",
        "# Define hyperparameters\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
        "    param_grid, cv=5, scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit with mapped labels\n",
        "grid.fit(X_train, y_train_mapped)\n",
        "\n",
        "# Best model\n",
        "best_xgb = grid.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)  # X_test is unchanged\n",
        "\n",
        "# Evaluation\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test_mapped, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test_mapped, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test_mapped, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test_mapped, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_mapped, y_pred, cmap='Purples')\n",
        "\n"
      ],
      "metadata": {
        "id": "GuPMoVFIXw72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights for XGBoost**\n",
        "\n",
        "(Best Params: learning_rate=0.1, max_depth=5, n_estimators=100)\n",
        "\n",
        "The model achieves ~44% accuracy, comparable to Gradient Boosting.\n",
        "\n",
        "1. Class 2 is predicted best (recall = 0.72, F1 = 0.53), showing that XGBoost effectively captures its structure.\n",
        "\n",
        "2. Class 3 is moderately predicted (recall = 0.44, precision = 0.53), reflecting a balanced but not perfect performance.\n",
        "\n",
        "3. Class 1 has very low recall (0.12) despite high precision (0.67), meaning the model only predicts it in a few confident cases but misses most instances.\n",
        "\n",
        "4. Class 4 is poorly predicted (recall = 0.12), suggesting overlap with other classes.\n",
        "\n",
        "5. No samples for Class 0 in the test set, so no evaluation was possible there.\n",
        "\n",
        "Overall, XGBoost provides strong predictive power for some classes (esp. Class 2) but struggles with minority/edge classes, similar to Gradient Boosting.\n",
        "\n",
        "------------------"
      ],
      "metadata": {
        "id": "XdZx9BC4hcuK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wat2dJttW_dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Light GBM (No Tuning)**"
      ],
      "metadata": {
        "id": "A6eDclhNdzVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "# Replace special characters\n",
        "X_train.columns = X_train.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)\n",
        "X_test.columns = X_test.columns.str.replace(r'[^A-Za-z0-9_]+', '_', regex=True)\n",
        "\n",
        "# Make columns unique (append suffix if duplicate)(as model cant handle duplicates)\n",
        "def make_columns_unique(columns):\n",
        "    seen = {}\n",
        "    result = []\n",
        "    for col in columns:\n",
        "        if col not in seen:\n",
        "            seen[col] = 0\n",
        "            result.append(col)\n",
        "        else:\n",
        "            seen[col] += 1\n",
        "            result.append(f\"{col}_{seen[col]}\")\n",
        "    return result\n",
        "\n",
        "X_train.columns = make_columns_unique(X_train.columns)\n",
        "X_test.columns = make_columns_unique(X_test.columns)\n",
        "\n",
        "# Align test columns\n",
        "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "\n",
        "#Map labels to 0-based (for XGBoost & LightGBM)\n",
        "y_train_mapped = y_train - 1\n",
        "y_test_mapped = y_test - 1\n",
        "\n",
        "\n",
        "# Train LightGBM\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "lgb_model.fit(X_train, y_train)\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='cool')\n"
      ],
      "metadata": {
        "id": "jVv2atFwW_Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Light GBM (With Hyperparameter Tuning)**"
      ],
      "metadata": {
        "id": "YaVRAbVEdc5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'num_leaves': [31, 50, 100]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(lgb.LGBMClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_lgb = grid.best_estimator_\n",
        "y_pred = best_lgb.predict(X_test)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted', zero_division=0))\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='cool')\n"
      ],
      "metadata": {
        "id": "rqjmmyyqW_VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights for LightGBM**\n",
        "\n",
        "(Best Params: learning_rate=0.01, n_estimators=150, num_leaves=31)\n",
        "\n",
        "The model achieves ~39% accuracy, slightly weaker than Gradient Boosting and XGBoost.\n",
        "\n",
        "1. Class 3 performs best (recall = 0.64, F1 = 0.47), showing LightGBM can detect this majority class relatively well.\n",
        "\n",
        "2. Class 4 is predicted moderately (recall = 0.42, precision = 0.42), reflecting balanced but limited performance.\n",
        "\n",
        "3. Class 2 has high precision (0.67) but very low recall (0.12), meaning predictions are cautious but miss most true instances.\n",
        "\n",
        "4. Class 5 is rarely captured (recall = 0.06), showing difficulty in distinguishing minority categories.\n",
        "\n",
        "Overall, LightGBM shows potential but underperforms compared to Gradient Boosting and XGBoost, likely due to parameter sensitivity and data imbalance.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "Jf6E_4MTh0Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion for Low Accuracy of all the above Predictive Models**\n",
        "\n",
        "---------\n",
        "\n",
        "The low accuracy (~40–45%) is mainly due to data limitations rather than model flaws:\n",
        "\n",
        "\n",
        "**Class imbalance:** Some ratings occur more frequently than others, making it hard for models to predict minority classes.\n",
        "\n",
        "**Small dataset**: With only ~100 test samples, models cannot learn complex patterns reliably.\n",
        "\n",
        "**Weak or noisy features:**  Many features may not strongly correlate with the target, and ratings can be subjective or inconsistent.\n",
        "\n",
        "**Multi-class challenge:** With 5 classes, even random guessing yields ~20% accuracy; distinguishing classes slightly better explains 40–45%.\n",
        "\n",
        "**Sparse categorical data:** One-hot encoding creates many sparse features; distance-based models (KNN) and ensembles struggle.\n",
        "\n",
        "**Hyperparameter tuning limits:** With small/noisy data, tuning rarely boosts accuracy significantly.\n",
        "\n",
        "**Ways to improve:** handle class imbalance (oversampling, class weights), reduce irrelevant features, combine categories to reduce sparsity, try simpler models (Naive Bayes), or ensemble multiple models.\n",
        "\n",
        "---------------------------------\n",
        "\n",
        "# **Bottom line:** For small, noisy, multi-class, and sparse datasets, 40–45% accuracy is expected and reflects data constraints rather than model failure."
      ],
      "metadata": {
        "id": "EWt9jz3WcifZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------\n",
        "\n",
        "# **Final Summary**\n",
        "\n",
        "1. Model accuracies ranged from 30% (KNN) to 45% (Gradient Boosting, XGBoost).\n",
        "\n",
        "2. Boosting models (XGBoost, Gradient Boosting) performed best, while KNN struggled the most.\n",
        "\n",
        "3. Class 3 was consistently well-predicted, whereas Classes 2, 4, and especially 5 often suffered from misclassification due to imbalance and overlapping features.\n",
        "\n",
        "4. Errors mainly occurred between neighboring ratings, suggesting insufficient feature separation.\n",
        "\n",
        "---------------------------------------\n",
        "\n",
        "# **Conclusion**\n",
        "\n",
        "Boosting models offer the strongest performance but still achieve only moderate accuracy. Improvements should focus on feature engineering, class balancing, and advanced modeling to better handle minority and overlapping classes."
      ],
      "metadata": {
        "id": "ov3VvgXTjGo6"
      }
    }
  ]
}